Parameter-Efficient Fine-Tuning (PEFT) techniques are methods designed to fine-tune Large Language Models (LLMs) efficiently without needing to adjust all the model's
parameters. Of retraining the entire model, these methods focus on updating only a small subset of parameters,
which reduces the computational cost and memory requirements instead while maintaining or even enhancing performance on specific tasks. 

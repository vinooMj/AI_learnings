Turn Your LLM into a Personal Chatbot with Just Docker + n8n!

I just unlocked something crazy powerful. 

✅ Real-time chat
✅ LLM responses
✅ Fully local + no OpenAI API keys
✅ Privacy-first AI setup
✅ All orchestrated visually in n8n



I used Docker Model Runner to host a local LLM (like smollm2), then connected it with n8n’s HTTP node and a simple chat input trigger. The flow?

When Chat Message Received
→ Docker Model Runner (your LLM inference engine)
→ Set Response Text

 End result: A chat interface that replies with your own LLM — NO cloud needed.
